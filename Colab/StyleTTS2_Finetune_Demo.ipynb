{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Yash-Kumar-tech/Colab-Notebooks/blob/main/Colab/StyleTTS2_Finetune_Demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Install packages and download models"
      ],
      "metadata": {
        "id": "yLqBa4uYPrqE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "# git clone https://github.com/yl4579/StyleTTS2.git\n",
        "# cd StyleTTS2\n",
        "pip install SoundFile torchaudio munch \"torch<2.5\" pydub pyyaml librosa nltk matplotlib accelerate transformers phonemizer einops einops-exts tqdm typing-extensions git+https://github.com/resemble-ai/monotonic_align.git\n",
        "sudo apt-get install espeak-ng\n",
        "git-lfs clone https://huggingface.co/yl4579/StyleTTS2-LibriTTS\n",
        "mv StyleTTS2-LibriTTS/Models ."
      ],
      "metadata": {
        "id": "H72WF06ZPrTF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4985f1f0-d03b-4118-ffe4-1cbdc2170300"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/resemble-ai/monotonic_align.git\n",
            "  Cloning https://github.com/resemble-ai/monotonic_align.git to /tmp/pip-req-build-oocownc5\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/resemble-ai/monotonic_align.git /tmp/pip-req-build-oocownc5\n",
            "  Resolved https://github.com/resemble-ai/monotonic_align.git to commit 78b985be210a03d08bc3acc01c4df0442105366f\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: SoundFile in /usr/local/lib/python3.11/dist-packages (0.13.1)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: munch in /usr/local/lib/python3.11/dist-packages (4.0.0)\n",
            "Collecting torch<2.5\n",
            "  Downloading torch-2.4.1-cp311-cp311-manylinux1_x86_64.whl.metadata (26 kB)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.11/dist-packages (0.25.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (6.0.2)\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.11/dist-packages (0.11.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.7.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.52.3)\n",
            "Requirement already satisfied: phonemizer in /usr/local/lib/python3.11/dist-packages (3.3.0)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (0.8.1)\n",
            "Requirement already satisfied: einops-exts in /usr/local/lib/python3.11/dist-packages (0.0.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (4.13.2)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from SoundFile) (1.17.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from SoundFile) (2.0.2)\n",
            "INFO: pip is looking at multiple versions of torchaudio to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting torchaudio\n",
            "  Downloading torchaudio-2.7.1-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (6.6 kB)\n",
            "  Downloading torchaudio-2.7.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (6.6 kB)\n",
            "  Downloading torchaudio-2.6.0-cp311-cp311-manylinux1_x86_64.whl.metadata (6.6 kB)\n",
            "  Downloading torchaudio-2.5.1-cp311-cp311-manylinux1_x86_64.whl.metadata (6.4 kB)\n",
            "  Downloading torchaudio-2.5.0-cp311-cp311-manylinux1_x86_64.whl.metadata (6.4 kB)\n",
            "  Downloading torchaudio-2.4.1-cp311-cp311-manylinux1_x86_64.whl.metadata (6.4 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch<2.5) (3.18.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch<2.5) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<2.5) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<2.5) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch<2.5) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch<2.5)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch<2.5)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch<2.5)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch<2.5) (9.1.0.70)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch<2.5)\n",
            "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch<2.5)\n",
            "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch<2.5)\n",
            "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch<2.5)\n",
            "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch<2.5)\n",
            "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch<2.5)\n",
            "  Downloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch<2.5)\n",
            "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting triton==3.0.0 (from torch<2.5)\n",
            "  Downloading triton-3.0.0-1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch<2.5) (12.4.127)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.11/dist-packages (from librosa) (3.0.1)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.60.0)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.15.3)\n",
            "Requirement already satisfied: scikit-learn>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.6.1)\n",
            "Requirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.5.1)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (4.4.2)\n",
            "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.8.2)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.5.0.post1)\n",
            "Requirement already satisfied: lazy_loader>=0.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.1.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.2.1)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.58.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (0.32.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from accelerate) (0.5.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: segments in /usr/local/lib/python3.11/dist-packages (from phonemizer) (2.3.0)\n",
            "Requirement already satisfied: attrs>=18.1 in /usr/local/lib/python3.11/dist-packages (from phonemizer) (25.3.0)\n",
            "Requirement already satisfied: dlinfo in /usr/local/lib/python3.11/dist-packages (from phonemizer) (2.0.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->SoundFile) (2.22)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.21.0->accelerate) (1.1.2)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.51.0->librosa) (0.43.0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.1->librosa) (4.3.8)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.4.26)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.1.0->librosa) (3.6.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<2.5) (3.0.2)\n",
            "Requirement already satisfied: csvw>=1.5.6 in /usr/local/lib/python3.11/dist-packages (from segments->phonemizer) (3.5.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch<2.5) (1.3.0)\n",
            "Requirement already satisfied: isodate in /usr/local/lib/python3.11/dist-packages (from csvw>=1.5.6->segments->phonemizer) (0.7.2)\n",
            "Requirement already satisfied: rfc3986<2 in /usr/local/lib/python3.11/dist-packages (from csvw>=1.5.6->segments->phonemizer) (1.5.0)\n",
            "Requirement already satisfied: uritemplate>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from csvw>=1.5.6->segments->phonemizer) (4.1.1)\n",
            "Requirement already satisfied: babel in /usr/local/lib/python3.11/dist-packages (from csvw>=1.5.6->segments->phonemizer) (2.17.0)\n",
            "Requirement already satisfied: language-tags in /usr/local/lib/python3.11/dist-packages (from csvw>=1.5.6->segments->phonemizer) (1.2.0)\n",
            "Requirement already satisfied: rdflib in /usr/local/lib/python3.11/dist-packages (from csvw>=1.5.6->segments->phonemizer) (7.1.4)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.11/dist-packages (from csvw>=1.5.6->segments->phonemizer) (0.4.6)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.11/dist-packages (from csvw>=1.5.6->segments->phonemizer) (4.24.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema->csvw>=1.5.6->segments->phonemizer) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema->csvw>=1.5.6->segments->phonemizer) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema->csvw>=1.5.6->segments->phonemizer) (0.25.1)\n",
            "Downloading torchaudio-2.4.1-cp311-cp311-manylinux1_x86_64.whl (3.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m69.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torch-2.4.1-cp311-cp311-manylinux1_x86_64.whl (797.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m797.1/797.1 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m112.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m92.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m59.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m172.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Download dataset (LJSpeech, 200 samples, ~15 minutes of data)\n",
        "\n",
        "You can definitely do it with fewer samples. This is just a proof of concept with 200 smaples."
      ],
      "metadata": {
        "id": "G398sL8wPzTB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd StyleTTS2\n",
        "!rm -rf Data"
      ],
      "metadata": {
        "id": "kJuQUBrEPy5C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7eb23a9e-fc94-4d24-feb8-31ecd4f4ce6a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/StyleTTS2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://drive.google.com/uc?id=1vqz26D3yn7OXS2vbfYxfSnpLS6m6tOFP"
      ],
      "metadata": {
        "id": "ABfDBnZe5C8D",
        "outputId": "9bb55b5a-4763-4a3f-a23a-3e2aea838b98",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-06-05 07:00:41--  https://drive.google.com/uc?id=1vqz26D3yn7OXS2vbfYxfSnpLS6m6tOFP\n",
            "Resolving drive.google.com (drive.google.com)... 173.194.69.138, 173.194.69.100, 173.194.69.113, ...\n",
            "Connecting to drive.google.com (drive.google.com)|173.194.69.138|:443... connected.\n",
            "HTTP request sent, awaiting response... 303 See Other\n",
            "Location: https://drive.usercontent.google.com/download?id=1vqz26D3yn7OXS2vbfYxfSnpLS6m6tOFP [following]\n",
            "--2025-06-05 07:00:41--  https://drive.usercontent.google.com/download?id=1vqz26D3yn7OXS2vbfYxfSnpLS6m6tOFP\n",
            "Resolving drive.usercontent.google.com (drive.usercontent.google.com)... 108.177.127.132, 2a00:1450:4013:c07::84\n",
            "Connecting to drive.usercontent.google.com (drive.usercontent.google.com)|108.177.127.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://accounts.google.com/ServiceLogin?service=wise&passive=1209600&continue=https://drive.usercontent.google.com/download?id%3D1vqz26D3yn7OXS2vbfYxfSnpLS6m6tOFP&followup=https://drive.usercontent.google.com/download?id%3D1vqz26D3yn7OXS2vbfYxfSnpLS6m6tOFP [following]\n",
            "--2025-06-05 07:00:42--  https://accounts.google.com/ServiceLogin?service=wise&passive=1209600&continue=https://drive.usercontent.google.com/download?id%3D1vqz26D3yn7OXS2vbfYxfSnpLS6m6tOFP&followup=https://drive.usercontent.google.com/download?id%3D1vqz26D3yn7OXS2vbfYxfSnpLS6m6tOFP\n",
            "Resolving accounts.google.com (accounts.google.com)... 108.177.119.84, 2a00:1450:4013:c14::54\n",
            "Connecting to accounts.google.com (accounts.google.com)|108.177.119.84|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://accounts.google.com/InteractiveLogin?continue=https://drive.usercontent.google.com/download?id%3D1vqz26D3yn7OXS2vbfYxfSnpLS6m6tOFP&followup=https://drive.usercontent.google.com/download?id%3D1vqz26D3yn7OXS2vbfYxfSnpLS6m6tOFP&passive=1209600&service=wise&ifkv=AdBytiPmKgHyT6hJ8ayf3nLDOJYORnNIMTLUGlYSY6L4o5AsoLhTh7lc1LCQbaylaX1p9kkLt37B [following]\n",
            "--2025-06-05 07:00:42--  https://accounts.google.com/InteractiveLogin?continue=https://drive.usercontent.google.com/download?id%3D1vqz26D3yn7OXS2vbfYxfSnpLS6m6tOFP&followup=https://drive.usercontent.google.com/download?id%3D1vqz26D3yn7OXS2vbfYxfSnpLS6m6tOFP&passive=1209600&service=wise&ifkv=AdBytiPmKgHyT6hJ8ayf3nLDOJYORnNIMTLUGlYSY6L4o5AsoLhTh7lc1LCQbaylaX1p9kkLt37B\n",
            "Reusing existing connection to accounts.google.com:443.\n",
            "HTTP request sent, awaiting response... 302 Moved Temporarily\n",
            "Location: https://accounts.google.com/v3/signin/identifier?continue=https%3A%2F%2Fdrive.usercontent.google.com%2Fdownload%3Fid%3D1vqz26D3yn7OXS2vbfYxfSnpLS6m6tOFP&followup=https%3A%2F%2Fdrive.usercontent.google.com%2Fdownload%3Fid%3D1vqz26D3yn7OXS2vbfYxfSnpLS6m6tOFP&ifkv=AdBytiMU3CrtEAnYwTMrXcdmMH2h1uS3DJTD4uHSE_Yv0SVo3TqbIezPE2eA0JO-TtlP5LbM0mV1&passive=1209600&service=wise&flowName=WebLiteSignIn&flowEntry=ServiceLogin&dsh=S757203395%3A1749106842060791 [following]\n",
            "--2025-06-05 07:00:42--  https://accounts.google.com/v3/signin/identifier?continue=https%3A%2F%2Fdrive.usercontent.google.com%2Fdownload%3Fid%3D1vqz26D3yn7OXS2vbfYxfSnpLS6m6tOFP&followup=https%3A%2F%2Fdrive.usercontent.google.com%2Fdownload%3Fid%3D1vqz26D3yn7OXS2vbfYxfSnpLS6m6tOFP&ifkv=AdBytiMU3CrtEAnYwTMrXcdmMH2h1uS3DJTD4uHSE_Yv0SVo3TqbIezPE2eA0JO-TtlP5LbM0mV1&passive=1209600&service=wise&flowName=WebLiteSignIn&flowEntry=ServiceLogin&dsh=S757203395%3A1749106842060791\n",
            "Reusing existing connection to accounts.google.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘uc?id=1vqz26D3yn7OXS2vbfYxfSnpLS6m6tOFP’\n",
            "\n",
            "uc?id=1vqz26D3yn7OX     [ <=>                ] 542.12K  --.-KB/s    in 0.04s   \n",
            "\n",
            "2025-06-05 07:00:42 (11.9 MB/s) - ‘uc?id=1vqz26D3yn7OXS2vbfYxfSnpLS6m6tOFP’ saved [555129]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown --id 1vqz26D3yn7OXS2vbfYxfSnpLS6m6tOFP\n",
        "!unzip Data.zip"
      ],
      "metadata": {
        "id": "mDXW8ZZePuSb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1529c31e-6bcc-47fc-edcd-79260922848c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/gdown/__main__.py:140: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Failed to retrieve file url:\n",
            "\n",
            "\tCannot retrieve the public link of the file. You may need to change\n",
            "\tthe permission to 'Anyone with the link', or have had many accesses.\n",
            "\tCheck FAQ in https://github.com/wkentaro/gdown?tab=readme-ov-file#faq.\n",
            "\n",
            "You may still be able to access the file from the browser:\n",
            "\n",
            "\thttps://drive.google.com/uc?id=1vqz26D3yn7OXS2vbfYxfSnpLS6m6tOFP\n",
            "\n",
            "but Gdown can't. Please check connections and permissions.\n",
            "unzip:  cannot find or open Data.zip, Data.zip.zip or Data.zip.ZIP.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Change the finetuning config\n",
        "\n",
        "Depending on the GPU you got, you may want to change the bacth size, max audio length, epiochs and so on."
      ],
      "metadata": {
        "id": "_AlBQREWU8ud"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "config_path = \"Configs/config_ft.yml\"\n",
        "\n",
        "import yaml\n",
        "config = yaml.safe_load(open(config_path))"
      ],
      "metadata": {
        "id": "7uEITi0hU4I2"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config['data_params']['root_path'] = \"Data/wavs\"\n",
        "\n",
        "config['batch_size'] = 2 # not enough RAM\n",
        "config['max_len'] = 100 # not enough RAM\n",
        "config['loss_params']['joint_epoch'] = 110 # we do not do SLM adversarial training due to not enough RAM\n",
        "\n",
        "with open(config_path, 'w') as outfile:\n",
        "  yaml.dump(config, outfile, default_flow_style=True)"
      ],
      "metadata": {
        "id": "TPTRgOKSVT4K"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Start finetuning\n"
      ],
      "metadata": {
        "id": "uUuB_19NWj2Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python train_finetune.py --config_path ./Configs/config_ft.yml"
      ],
      "metadata": {
        "id": "HZVAD5GKWm-O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca715ade-bec7-4a69-d557-b4682e58cb9a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-06-05 06:59:03.341004: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1749106743.603634    1856 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1749106743.672066    1856 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-06-05 06:59:04.239657: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/StyleTTS2/train_finetune.py\", line 707, in <module>\n",
            "    main()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/click/core.py\", line 1442, in __call__\n",
            "    return self.main(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/click/core.py\", line 1363, in main\n",
            "    rv = self.invoke(ctx)\n",
            "         ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/click/core.py\", line 1226, in invoke\n",
            "    return ctx.invoke(self.callback, **ctx.params)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/click/core.py\", line 794, in invoke\n",
            "    return callback(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/StyleTTS2/train_finetune.py\", line 90, in main\n",
            "    train_list, val_list = get_data_path_list(train_path, val_path)\n",
            "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/StyleTTS2/utils.py\", line 35, in get_data_path_list\n",
            "    with open(train_path, 'r', encoding='utf-8', errors='ignore') as f:\n",
            "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "FileNotFoundError: [Errno 2] No such file or directory: 'Data/train_list.txt'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test the model quality\n",
        "\n",
        "Note that this mainly serves as a proof of concept due to RAM limitation of free Colab instances. A lot of settings are suboptimal. In the future when DDP works for train_second.py, we will also add mixed precision finetuning to save time and RAM. You can also add SLM adversarial training run if you have paid Colab services (such as A100 with 40G of RAM)."
      ],
      "metadata": {
        "id": "I0_7wsGkXGfc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "id": "OPLphjbncE7p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "478b9d4f-ef5d-4cd7-c512-dba54e52324a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "torch.manual_seed(0)\n",
        "torch.backends.cudnn.benchmark = False\n",
        "torch.backends.cudnn.deterministic = True\n",
        "\n",
        "import random\n",
        "random.seed(0)\n",
        "\n",
        "import numpy as np\n",
        "np.random.seed(0)\n",
        "\n",
        "# load packages\n",
        "import time\n",
        "import random\n",
        "import yaml\n",
        "from munch import Munch\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "import torchaudio\n",
        "import librosa\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "from models import *\n",
        "from utils import *\n",
        "from text_utils import TextCleaner\n",
        "textclenaer = TextCleaner()\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "to_mel = torchaudio.transforms.MelSpectrogram(\n",
        "    n_mels=80, n_fft=2048, win_length=1200, hop_length=300)\n",
        "mean, std = -4, 4\n",
        "\n",
        "def length_to_mask(lengths):\n",
        "    mask = torch.arange(lengths.max()).unsqueeze(0).expand(lengths.shape[0], -1).type_as(lengths)\n",
        "    mask = torch.gt(mask+1, lengths.unsqueeze(1))\n",
        "    return mask\n",
        "\n",
        "def preprocess(wave):\n",
        "    wave_tensor = torch.from_numpy(wave).float()\n",
        "    mel_tensor = to_mel(wave_tensor)\n",
        "    mel_tensor = (torch.log(1e-5 + mel_tensor.unsqueeze(0)) - mean) / std\n",
        "    return mel_tensor\n",
        "\n",
        "def compute_style(path):\n",
        "    wave, sr = librosa.load(path, sr=24000)\n",
        "    audio, index = librosa.effects.trim(wave, top_db=30)\n",
        "    if sr != 24000:\n",
        "        audio = librosa.resample(audio, sr, 24000)\n",
        "    mel_tensor = preprocess(audio).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        ref_s = model.style_encoder(mel_tensor.unsqueeze(1))\n",
        "        ref_p = model.predictor_encoder(mel_tensor.unsqueeze(1))\n",
        "\n",
        "    return torch.cat([ref_s, ref_p], dim=1)\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "# load phonemizer\n",
        "import phonemizer\n",
        "global_phonemizer = phonemizer.backend.EspeakBackend(language='en-us', preserve_punctuation=True,  with_stress=True)\n",
        "\n",
        "config = yaml.safe_load(open(\"Models/LJSpeech/config_ft.yml\"))\n",
        "\n",
        "# load pretrained ASR model\n",
        "ASR_config = config.get('ASR_config', False)\n",
        "ASR_path = config.get('ASR_path', False)\n",
        "text_aligner = load_ASR_models(ASR_path, ASR_config)\n",
        "\n",
        "# load pretrained F0 model\n",
        "F0_path = config.get('F0_path', False)\n",
        "pitch_extractor = load_F0_models(F0_path)\n",
        "\n",
        "# load BERT model\n",
        "from Utils.PLBERT.util import load_plbert\n",
        "BERT_path = config.get('PLBERT_dir', False)\n",
        "plbert = load_plbert(BERT_path)\n",
        "\n",
        "model_params = recursive_munch(config['model_params'])\n",
        "model = build_model(model_params, text_aligner, pitch_extractor, plbert)\n",
        "_ = [model[key].eval() for key in model]\n",
        "_ = [model[key].to(device) for key in model]"
      ],
      "metadata": {
        "id": "jIIAoDACXJL0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 495
        },
        "outputId": "a39012a0-53b6-457a-8482-d75c1f98ceef"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "177\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "UnpicklingError",
          "evalue": "Weights only load failed. This file can still be loaded, to do so you have two options, \u001b[1mdo those steps only if you trust the source of the checkpoint\u001b[0m. \n\t(1) In PyTorch 2.6, we changed the default value of the `weights_only` argument in `torch.load` from `False` to `True`. Re-running `torch.load` with `weights_only` set to `False` will likely succeed, but it can result in arbitrary code execution. Do it only if you got the file from a trusted source.\n\t(2) Alternatively, to load with `weights_only=True` please check the recommended steps in the following error message.\n\tWeightsUnpickler error: Unsupported global: GLOBAL builtins.getattr was not an allowed global by default. Please use `torch.serialization.add_safe_globals([getattr])` or the `torch.serialization.safe_globals([getattr])` context manager to allowlist this global if you trust this class/function.\n\nCheck the documentation of torch.load to learn more about types accepted by default with weights_only https://pytorch.org/docs/stable/generated/torch.load.html.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mUnpicklingError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-aa766310be72>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0mASR_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ASR_config'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0mASR_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ASR_path'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m \u001b[0mtext_aligner\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_ASR_models\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mASR_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mASR_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;31m# load pretrained F0 model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/StyleTTS2/models.py\u001b[0m in \u001b[0;36mload_ASR_models\u001b[0;34m(ASR_MODEL_PATH, ASR_MODEL_CONFIG)\u001b[0m\n\u001b[1;32m    607\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    608\u001b[0m     \u001b[0masr_model_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_load_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mASR_MODEL_CONFIG\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 609\u001b[0;31m     \u001b[0masr_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_load_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0masr_model_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mASR_MODEL_PATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    610\u001b[0m     \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0masr_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    611\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/StyleTTS2/models.py\u001b[0m in \u001b[0;36m_load_model\u001b[0;34m(model_config, model_path)\u001b[0m\n\u001b[1;32m    602\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_load_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    603\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mASRCNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mmodel_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 604\u001b[0;31m         \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'cpu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    605\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    606\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1468\u001b[0m                         )\n\u001b[1;32m   1469\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUnpicklingError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1470\u001b[0;31m                         \u001b[0;32mraise\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUnpicklingError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_get_wo_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1471\u001b[0m                 return _load(\n\u001b[1;32m   1472\u001b[0m                     \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mUnpicklingError\u001b[0m: Weights only load failed. This file can still be loaded, to do so you have two options, \u001b[1mdo those steps only if you trust the source of the checkpoint\u001b[0m. \n\t(1) In PyTorch 2.6, we changed the default value of the `weights_only` argument in `torch.load` from `False` to `True`. Re-running `torch.load` with `weights_only` set to `False` will likely succeed, but it can result in arbitrary code execution. Do it only if you got the file from a trusted source.\n\t(2) Alternatively, to load with `weights_only=True` please check the recommended steps in the following error message.\n\tWeightsUnpickler error: Unsupported global: GLOBAL builtins.getattr was not an allowed global by default. Please use `torch.serialization.add_safe_globals([getattr])` or the `torch.serialization.safe_globals([getattr])` context manager to allowlist this global if you trust this class/function.\n\nCheck the documentation of torch.load to learn more about types accepted by default with weights_only https://pytorch.org/docs/stable/generated/torch.load.html."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "files = [f for f in os.listdir(\"Models/LJSpeech/\") if f.endswith('.pth')]\n",
        "sorted_files = sorted(files, key=lambda x: int(x.split('_')[-1].split('.')[0]))"
      ],
      "metadata": {
        "id": "eKXRAyyzcMpQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "params_whole = torch.load(\"Models/LJSpeech/\" + sorted_files[-1], map_location='cpu')\n",
        "params = params_whole['net']"
      ],
      "metadata": {
        "id": "ULuU9-VDb9Pk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for key in model:\n",
        "    if key in params:\n",
        "        print('%s loaded' % key)\n",
        "        try:\n",
        "            model[key].load_state_dict(params[key])\n",
        "        except:\n",
        "            from collections import OrderedDict\n",
        "            state_dict = params[key]\n",
        "            new_state_dict = OrderedDict()\n",
        "            for k, v in state_dict.items():\n",
        "                name = k[7:] # remove `module.`\n",
        "                new_state_dict[name] = v\n",
        "            # load params\n",
        "            model[key].load_state_dict(new_state_dict, strict=False)\n",
        "#             except:\n",
        "#                 _load(params[key], model[key])\n",
        "_ = [model[key].eval() for key in model]"
      ],
      "metadata": {
        "id": "J-U29yIYc2ea"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from Modules.diffusion.sampler import DiffusionSampler, ADPM2Sampler, KarrasSchedule"
      ],
      "metadata": {
        "id": "jrPQ_Yrwc3n6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sampler = DiffusionSampler(\n",
        "    model.diffusion.diffusion,\n",
        "    sampler=ADPM2Sampler(),\n",
        "    sigma_schedule=KarrasSchedule(sigma_min=0.0001, sigma_max=3.0, rho=9.0), # empirical parameters\n",
        "    clamp=False\n",
        ")"
      ],
      "metadata": {
        "id": "n2CWYNoqc455"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def inference(text, ref_s, alpha = 0.3, beta = 0.7, diffusion_steps=5, embedding_scale=1):\n",
        "    text = text.strip()\n",
        "    ps = global_phonemizer.phonemize([text])\n",
        "    ps = word_tokenize(ps[0])\n",
        "    ps = ' '.join(ps)\n",
        "    tokens = textclenaer(ps)\n",
        "    tokens.insert(0, 0)\n",
        "    tokens = torch.LongTensor(tokens).to(device).unsqueeze(0)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        input_lengths = torch.LongTensor([tokens.shape[-1]]).to(device)\n",
        "        text_mask = length_to_mask(input_lengths).to(device)\n",
        "\n",
        "        t_en = model.text_encoder(tokens, input_lengths, text_mask)\n",
        "        bert_dur = model.bert(tokens, attention_mask=(~text_mask).int())\n",
        "        d_en = model.bert_encoder(bert_dur).transpose(-1, -2)\n",
        "\n",
        "        s_pred = sampler(noise = torch.randn((1, 256)).unsqueeze(1).to(device),\n",
        "                                          embedding=bert_dur,\n",
        "                                          embedding_scale=embedding_scale,\n",
        "                                            features=ref_s, # reference from the same speaker as the embedding\n",
        "                                             num_steps=diffusion_steps).squeeze(1)\n",
        "\n",
        "\n",
        "        s = s_pred[:, 128:]\n",
        "        ref = s_pred[:, :128]\n",
        "\n",
        "        ref = alpha * ref + (1 - alpha)  * ref_s[:, :128]\n",
        "        s = beta * s + (1 - beta)  * ref_s[:, 128:]\n",
        "\n",
        "        d = model.predictor.text_encoder(d_en,\n",
        "                                         s, input_lengths, text_mask)\n",
        "\n",
        "        x, _ = model.predictor.lstm(d)\n",
        "        duration = model.predictor.duration_proj(x)\n",
        "\n",
        "        duration = torch.sigmoid(duration).sum(axis=-1)\n",
        "        pred_dur = torch.round(duration.squeeze()).clamp(min=1)\n",
        "\n",
        "        pred_aln_trg = torch.zeros(input_lengths, int(pred_dur.sum().data))\n",
        "        c_frame = 0\n",
        "        for i in range(pred_aln_trg.size(0)):\n",
        "            pred_aln_trg[i, c_frame:c_frame + int(pred_dur[i].data)] = 1\n",
        "            c_frame += int(pred_dur[i].data)\n",
        "\n",
        "        # encode prosody\n",
        "        en = (d.transpose(-1, -2) @ pred_aln_trg.unsqueeze(0).to(device))\n",
        "        if model_params.decoder.type == \"hifigan\":\n",
        "            asr_new = torch.zeros_like(en)\n",
        "            asr_new[:, :, 0] = en[:, :, 0]\n",
        "            asr_new[:, :, 1:] = en[:, :, 0:-1]\n",
        "            en = asr_new\n",
        "\n",
        "        F0_pred, N_pred = model.predictor.F0Ntrain(en, s)\n",
        "\n",
        "        asr = (t_en @ pred_aln_trg.unsqueeze(0).to(device))\n",
        "        if model_params.decoder.type == \"hifigan\":\n",
        "            asr_new = torch.zeros_like(asr)\n",
        "            asr_new[:, :, 0] = asr[:, :, 0]\n",
        "            asr_new[:, :, 1:] = asr[:, :, 0:-1]\n",
        "            asr = asr_new\n",
        "\n",
        "        out = model.decoder(asr,\n",
        "                                F0_pred, N_pred, ref.squeeze().unsqueeze(0))\n",
        "\n",
        "\n",
        "    return out.squeeze().cpu().numpy()[..., :-50] # weird pulse at the end of the model, need to be fixed later"
      ],
      "metadata": {
        "id": "2x5kVb3nc_eY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Synthesize speech"
      ],
      "metadata": {
        "id": "O159JnwCc6CC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = '''Maltby and Company would issue warrants on them deliverable to the importer, and the goods were then passed to be stored in neighboring warehouses.\n",
        "'''"
      ],
      "metadata": {
        "id": "ThciXQ6rc9Eq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get a random reference in the training set, note that it doesn't matter which one you use\n",
        "path = \"Data/wavs/LJ001-0110.wav\"\n",
        "# this style vector ref_s can be saved as a parameter together with the model weights\n",
        "ref_s = compute_style(path)"
      ],
      "metadata": {
        "id": "jldPkJyCc83a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start = time.time()\n",
        "wav = inference(text, ref_s, alpha=0.9, beta=0.9, diffusion_steps=10, embedding_scale=1)\n",
        "rtf = (time.time() - start) / (len(wav) / 24000)\n",
        "print(f\"RTF = {rtf:5f}\")\n",
        "import IPython.display as ipd\n",
        "display(ipd.Audio(wav, rate=24000, normalize=False))"
      ],
      "metadata": {
        "id": "_mIU0jqDdQ-c"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}